{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2868ded4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Customer Segmentation & Classification - Project Akhir Data Mining\n",
    "\n",
    "## Overview\n",
    "Project ini melakukan analisis customer segmentation dan classification menggunakan data Online Retail II. \n",
    "\n",
    "### Tahapan Project:\n",
    "1. **Preprocessing Data Transaksi** - Membersihkan dan menyiapkan data transaksi\n",
    "2. **Customer Aggregation** - Agregasi data transaksi ke level pelanggan\n",
    "3. **Preprocessing Data Customer** - Mempersiapkan data customer untuk modeling\n",
    "4. **Classification Modeling** - Supervised Learning untuk prediksi High Value Customer\n",
    "5. **Customer Segmentation** - Unsupervised Learning menggunakan K-Means Clustering\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bb3095",
   "metadata": {},
   "source": [
    "## Part 1: Preprocessing Data Transaksi\n",
    "\n",
    "Tahap pertama adalah membersihkan dan mempersiapkan data transaksi online retail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cc0dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ“ Libraries berhasil di-import\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b5e01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv('FinalDM/Raw/online_retail_II.csv')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATA BERHASIL DIMUAT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Jumlah baris: {df.shape[0]:,}\")\n",
    "print(f\"Jumlah kolom: {df.shape[1]}\")\n",
    "print(f\"\\nKolom-kolom dalam dataset:\")\n",
    "print(df.columns.tolist())\n",
    "print(f\"\\n5 Baris Pertama:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dffa86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informasi Dataset\n",
    "print(\"=\"*60)\n",
    "print(\"INFORMASI DATASET\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTipe Data:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\nStatistik Deskriptif:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240eaf65",
   "metadata": {},
   "source": [
    "### 1.1 Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf00a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Missing Values\n",
    "print(\"=\"*60)\n",
    "print(\"HANDLE MISSING VALUES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Hapus baris dengan missing di kolom krusial\n",
    "initial_rows = len(df)\n",
    "df = df.dropna(subset=['Invoice', 'StockCode', 'Customer ID'])\n",
    "removed = initial_rows - len(df)\n",
    "print(f\"\\nâœ“ Dihapus {removed:,} baris dengan missing Invoice/StockCode/Customer ID\")\n",
    "\n",
    "# Isi missing Description dan Country\n",
    "df['Description'].fillna('Unknown', inplace=True)\n",
    "df['Country'].fillna('Unknown', inplace=True)\n",
    "print(f\"âœ“ Missing Description & Country diisi dengan 'Unknown'\")\n",
    "\n",
    "print(f\"\\nJumlah baris sekarang: {len(df):,}\")\n",
    "print(f\"Missing values setelah handling:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dbbf5d",
   "metadata": {},
   "source": [
    "### 1.2 Remove Duplicates & Handle Negative Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41829c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Duplicates\n",
    "print(\"=\"*60)\n",
    "print(\"REMOVE DUPLICATES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "initial_rows = len(df)\n",
    "df = df.drop_duplicates()\n",
    "duplicates_removed = initial_rows - len(df)\n",
    "print(f\"âœ“ Dihapus {duplicates_removed:,} baris duplikat\")\n",
    "\n",
    "# Handle Negative Values (cancellation/return)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"HANDLE NEGATIVE VALUES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "negative_quantity = (df['Quantity'] < 0).sum()\n",
    "print(f\"Transaksi dengan Quantity negatif: {negative_quantity:,}\")\n",
    "\n",
    "initial_rows = len(df)\n",
    "df = df[df['Quantity'] > 0]\n",
    "removed = initial_rows - len(df)\n",
    "print(f\"âœ“ Dihapus {removed:,} baris dengan Quantity negatif\")\n",
    "\n",
    "print(f\"\\nJumlah baris sekarang: {len(df):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f694c1",
   "metadata": {},
   "source": [
    "### 1.3 Data Type Conversion & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f8bd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Type Conversion\n",
    "print(\"=\"*60)\n",
    "print(\"DATA TYPE CONVERSION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Konversi InvoiceDate ke datetime\n",
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "df['Quantity'] = pd.to_numeric(df['Quantity'], errors='coerce').astype('int64')\n",
    "df['Price'] = pd.to_numeric(df['Price'], errors='coerce').astype('float64')\n",
    "df['Customer ID'] = df['Customer ID'].astype(str)\n",
    "\n",
    "print(\"âœ“ InvoiceDate -> datetime\")\n",
    "print(\"âœ“ Quantity -> int64\")\n",
    "print(\"âœ“ Price -> float64\")\n",
    "print(\"âœ“ Customer ID -> object\")\n",
    "\n",
    "# Feature Engineering\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# TotalAmount\n",
    "df['TotalAmount'] = df['Quantity'] * df['Price']\n",
    "print(\"âœ“ TotalAmount = Quantity Ã— Price\")\n",
    "\n",
    "# Time Features\n",
    "df['Year'] = df['InvoiceDate'].dt.year\n",
    "df['Month'] = df['InvoiceDate'].dt.month\n",
    "df['Day'] = df['InvoiceDate'].dt.day\n",
    "df['Hour'] = df['InvoiceDate'].dt.hour\n",
    "df['DayOfWeek'] = df['InvoiceDate'].dt.dayofweek\n",
    "df['IsWeekend'] = df['DayOfWeek'].isin([5, 6])\n",
    "\n",
    "print(\"âœ“ Fitur waktu: Year, Month, Day, Hour, DayOfWeek, IsWeekend\")\n",
    "\n",
    "print(f\"\\nJumlah kolom sekarang: {df.shape[1]}\")\n",
    "print(f\"Kolom baru: {['TotalAmount', 'Year', 'Month', 'Day', 'Hour', 'DayOfWeek', 'IsWeekend']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b338058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Preprocessed Data\n",
    "output_path = 'FinalDM/Raw/online_retail_II_preprocessed.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PREPROCESSING SELESAI\")\n",
    "print(\"=\"*60)\n",
    "print(f\"âœ“ Data berhasil disimpan: {output_path}\")\n",
    "print(f\"âœ“ Total baris: {len(df):,}\")\n",
    "print(f\"âœ“ Total kolom: {df.shape[1]}\")\n",
    "print(f\"âœ“ Periode: {df['InvoiceDate'].min()} s/d {df['InvoiceDate'].max()}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae8771b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Customer Aggregation\n",
    "\n",
    "Mengagregasi data transaksi ke level pelanggan untuk membuat fitur RFM (Recency, Frequency, Monetary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14d547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Preprocessed Data\n",
    "df_trans = pd.read_csv('FinalDM/Raw/online_retail_II_preprocessed.csv')\n",
    "df_trans['InvoiceDate'] = pd.to_datetime(df_trans['InvoiceDate'])\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATA PREPROCESSED DIMUAT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total transaksi: {len(df_trans):,}\")\n",
    "print(f\"Customer unik: {df_trans['Customer ID'].nunique():,}\")\n",
    "print(f\"Periode: {df_trans['InvoiceDate'].min()} s/d {df_trans['InvoiceDate'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ea8476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregasi ke Level Pelanggan\n",
    "print(\"=\"*60)\n",
    "print(\"AGREGASI KE LEVEL PELANGGAN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Tanggal acuan untuk Recency\n",
    "reference_date = df_trans['InvoiceDate'].max() + pd.Timedelta(days=1)\n",
    "print(f\"Tanggal acuan untuk Recency: {reference_date}\")\n",
    "\n",
    "# Agregasi per Customer ID\n",
    "customer_agg = df_trans.groupby('Customer ID').agg({\n",
    "    'TotalAmount': 'sum',           # TotalSpending\n",
    "    'Invoice': 'nunique',            # TotalTransaction\n",
    "    'Quantity': 'sum',               # TotalQuantity\n",
    "    'Price': 'mean',                 # AvgPrice\n",
    "    'InvoiceDate': 'max'             # Last Transaction Date\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns\n",
    "customer_agg.columns = ['CustomerID', 'TotalSpending', 'TotalTransaction', \n",
    "                        'TotalQuantity', 'AvgPrice', 'LastTransactionDate']\n",
    "\n",
    "# Hitung Recency\n",
    "customer_agg['Recency'] = (reference_date - customer_agg['LastTransactionDate']).dt.days\n",
    "\n",
    "# Bulatkan nilai\n",
    "customer_agg['AvgPrice'] = customer_agg['AvgPrice'].round(2)\n",
    "customer_agg['TotalSpending'] = customer_agg['TotalSpending'].round(2)\n",
    "\n",
    "print(f\"\\nâœ“ Agregasi selesai!\")\n",
    "print(f\"âœ“ Jumlah pelanggan: {len(customer_agg):,}\")\n",
    "\n",
    "customer_agg.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55893bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistik Fitur Agregasi\n",
    "print(\"=\"*60)\n",
    "print(\"STATISTIK FITUR AGREGASI\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for col in ['TotalSpending', 'TotalTransaction', 'TotalQuantity', 'AvgPrice', 'Recency']:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Min: {customer_agg[col].min():.2f}\")\n",
    "    print(f\"  Max: {customer_agg[col].max():.2f}\")\n",
    "    print(f\"  Mean: {customer_agg[col].mean():.2f}\")\n",
    "    print(f\"  Median: {customer_agg[col].median():.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TOP 10 CUSTOMER BY TOTAL SPENDING\")\n",
    "print(\"=\"*60)\n",
    "customer_agg.nlargest(10, 'TotalSpending')[['CustomerID', 'TotalSpending', 'TotalTransaction', 'Recency']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc51484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Customer Aggregated Data\n",
    "df_to_save = customer_agg.drop('LastTransactionDate', axis=1)\n",
    "output_path = 'FinalDM/Raw/customer_aggregated.csv'\n",
    "df_to_save.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CUSTOMER AGGREGATION SELESAI\")\n",
    "print(\"=\"*60)\n",
    "print(f\"âœ“ Data disimpan: {output_path}\")\n",
    "print(f\"âœ“ Total customer: {len(df_to_save):,}\")\n",
    "print(f\"âœ“ Fitur: {list(df_to_save.columns)}\")\n",
    "\n",
    "df_to_save.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7547cd7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Preprocessing Customer Data\n",
    "\n",
    "Mempersiapkan data customer untuk modeling dengan konversi tipe data dan validasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b2a48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Customer Aggregated Data\n",
    "df_cust = pd.read_csv('FinalDM/Raw/customer_aggregated.csv')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CUSTOMER DATA LOADED\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total customers: {len(df_cust):,}\")\n",
    "print(f\"Columns: {list(df_cust.columns)}\")\n",
    "print(f\"\\nData Info:\")\n",
    "print(df_cust.info())\n",
    "print(f\"\\nSample Data:\")\n",
    "df_cust.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5146e2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konversi CustomerID ke Object\n",
    "print(\"=\"*60)\n",
    "print(\"KONVERSI CUSTOMER ID\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"Tipe data sebelum: {df_cust['CustomerID'].dtype}\")\n",
    "\n",
    "# Handle missing values\n",
    "missing = df_cust['CustomerID'].isnull().sum()\n",
    "if missing > 0:\n",
    "    print(f\"Missing CustomerID: {missing}\")\n",
    "    df_cust = df_cust.dropna(subset=['CustomerID'])\n",
    "    \n",
    "# Konversi ke integer lalu ke object\n",
    "df_cust['CustomerID'] = df_cust['CustomerID'].astype('int64').astype('object')\n",
    "\n",
    "print(f\"Tipe data setelah: {df_cust['CustomerID'].dtype}\")\n",
    "print(f\"âœ“ CustomerID berhasil dikonversi ke object\")\n",
    "\n",
    "# Validasi Data\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VALIDASI DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Cek nilai negatif\n",
    "numeric_cols = df_cust.select_dtypes(include=[np.number]).columns\n",
    "for col in numeric_cols:\n",
    "    negative_count = (df_cust[col] < 0).sum()\n",
    "    print(f\"{col}: {negative_count} nilai negatif\")\n",
    "\n",
    "# Cek duplikat CustomerID\n",
    "duplicates = df_cust['CustomerID'].duplicated().sum()\n",
    "print(f\"\\nDuplikat CustomerID: {duplicates}\")\n",
    "print(\"âœ“ Data valid dan siap untuk modeling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82c98e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Preprocessed Customer Data\n",
    "output_path = 'FinalDM/Modelling/customer_aggregated_preprocessed.csv'\n",
    "df_cust.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CUSTOMER PREPROCESSING SELESAI\")\n",
    "print(\"=\"*60)\n",
    "print(f\"âœ“ Data disimpan: {output_path}\")\n",
    "print(f\"âœ“ Total customers: {len(df_cust):,}\")\n",
    "print(f\"âœ“ Siap untuk Classification & Clustering\")\n",
    "\n",
    "df_cust.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e532de7a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Classification Modeling - High Value Customer (HVC)\n",
    "\n",
    "Supervised Learning untuk memprediksi High Value Customer menggunakan Logistic Regression dan Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b737b900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries for Modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, confusion_matrix, classification_report)\n",
    "\n",
    "# Load Data\n",
    "df_model = pd.read_csv('FinalDM/Modelling/customer_aggregated_preprocessed.csv')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATA LOADED FOR MODELING\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total customers: {len(df_model):,}\")\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e14cb1",
   "metadata": {},
   "source": [
    "### 4.1 Create Target Variable: HVC (High Value Customer)\n",
    "\n",
    "HVC didefinisikan berdasarkan persentil ke-75 dari TotalSpending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ee932b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HVC Labels\n",
    "percentile_75 = df_model['TotalSpending'].quantile(0.75)\n",
    "df_model['HVC'] = (df_model['TotalSpending'] > percentile_75).astype(int)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"HIGH VALUE CUSTOMER (HVC) LABELS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Threshold (P75): Â£{percentile_75:,.2f}\")\n",
    "print(f\"\\nDistribusi HVC:\")\n",
    "print(df_model['HVC'].value_counts())\n",
    "print(f\"\\nPersentase:\")\n",
    "print(df_model['HVC'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Visualisasi\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Distribution\n",
    "df_model['HVC'].value_counts().plot(kind='bar', ax=axes[0], color=['#3498db', '#e74c3c'])\n",
    "axes[0].set_title('Distribusi HVC', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('HVC Label')\n",
    "axes[0].set_ylabel('Jumlah Customer')\n",
    "axes[0].set_xticklabels(['Non-HVC (0)', 'HVC (1)'], rotation=0)\n",
    "\n",
    "# TotalSpending Distribution by HVC\n",
    "df_model.boxplot(column='TotalSpending', by='HVC', ax=axes[1])\n",
    "axes[1].set_title('TotalSpending by HVC', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('HVC Label')\n",
    "axes[1].set_ylabel('TotalSpending (Â£)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a3d02e",
   "metadata": {},
   "source": [
    "### 4.2 Feature Selection & Train-Test Split\n",
    "\n",
    "Features: TotalTransaction, TotalQuantity, AvgPrice, Recency (tanpa TotalSpending untuk avoid data leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79ccb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection (exclude TotalSpending untuk avoid data leakage)\n",
    "feature_cols = ['TotalTransaction', 'TotalQuantity', 'AvgPrice', 'Recency']\n",
    "X = df_model[feature_cols]\n",
    "y = df_model['HVC']\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FEATURE SELECTION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Features: {feature_cols}\")\n",
    "print(f\"Target: HVC\")\n",
    "print(f\"\\nX shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "\n",
    "# Train-Test Split (80-20 dengan stratified sampling)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAIN-TEST SPLIT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Train: {len(X_train)} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"Test: {len(X_test)} samples ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"\\nTrain HVC distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\nTest HVC distribution:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31632a89",
   "metadata": {},
   "source": [
    "### 4.3 Model Training\n",
    "\n",
    "- **Logistic Regression**: Dengan StandardScaler\n",
    "- **Random Forest**: Tanpa scaling (tree-based model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba542eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: StandardScaler untuk Logistic Regression\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL 1: LOGISTIC REGRESSION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train Logistic Regression\n",
    "model_lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model_lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lr = model_lr.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
    "prec_lr = precision_score(y_test, y_pred_lr)\n",
    "rec_lr = recall_score(y_test, y_pred_lr)\n",
    "f1_lr = f1_score(y_test, y_pred_lr)\n",
    "\n",
    "print(f\"\\nâœ“ Logistic Regression trained!\")\n",
    "print(f\"Accuracy: {acc_lr:.4f}\")\n",
    "print(f\"Precision: {prec_lr:.4f}\")\n",
    "print(f\"Recall: {rec_lr:.4f}\")\n",
    "print(f\"F1-Score: {f1_lr:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL 2: RANDOM FOREST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train Random Forest (tanpa scaling)\n",
    "model_rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "prec_rf = precision_score(y_test, y_pred_rf)\n",
    "rec_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"\\nâœ“ Random Forest trained!\")\n",
    "print(f\"Accuracy: {acc_rf:.4f}\")\n",
    "print(f\"Precision: {prec_rf:.4f}\")\n",
    "print(f\"Recall: {rec_rf:.4f}\")\n",
    "print(f\"F1-Score: {f1_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118bd9d5",
   "metadata": {},
   "source": [
    "### 4.4 Model Evaluation & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5e621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Logistic Regression\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
    "axes[0].set_title('Confusion Matrix - Logistic Regression', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "\n",
    "# Random Forest\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens', ax=axes[1])\n",
    "axes[1].set_title('Confusion Matrix - Random Forest', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Metrics Comparison\n",
    "print(\"=\"*60)\n",
    "print(\"PERBANDINGAN MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Random Forest'],\n",
    "    'Accuracy': [acc_lr, acc_rf],\n",
    "    'Precision': [prec_lr, prec_rf],\n",
    "    'Recall': [rec_lr, rec_rf],\n",
    "    'F1-Score': [f1_lr, f1_rf]\n",
    "})\n",
    "\n",
    "print(metrics_df.to_string(index=False))\n",
    "\n",
    "# Bar plot comparison\n",
    "metrics_df.set_index('Model').plot(kind='bar', figsize=(10, 6), rot=0)\n",
    "plt.title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246c0bbe",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Customer Segmentation - K-Means Clustering\n",
    "\n",
    "Unsupervised Learning untuk mengelompokkan customer berdasarkan perilaku pembelian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad34ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries for Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load Data untuk Clustering\n",
    "df_cluster = pd.read_csv('FinalDM/Modelling/customer_aggregated_preprocessed.csv')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATA LOADED FOR CLUSTERING\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total customers: {len(df_cluster):,}\")\n",
    "print(f\"Columns: {list(df_cluster.columns)}\")\n",
    "df_cluster.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83afc14a",
   "metadata": {},
   "source": [
    "### 5.1 Feature Selection & Preprocessing\n",
    "\n",
    "Menggunakan 5 fitur numerik: TotalSpending, TotalTransaction, TotalQuantity, AvgPrice, Recency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded6531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection untuk Clustering\n",
    "cluster_features = ['TotalSpending', 'TotalTransaction', 'TotalQuantity', 'AvgPrice', 'Recency']\n",
    "X_cluster = df_cluster[cluster_features]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FEATURE SELECTION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Features: {cluster_features}\")\n",
    "print(f\"Shape: {X_cluster.shape}\")\n",
    "\n",
    "# Preprocessing: StandardScaler\n",
    "scaler_cluster = StandardScaler()\n",
    "X_cluster_scaled = scaler_cluster.fit_transform(X_cluster)\n",
    "\n",
    "print(\"\\nâœ“ Data berhasil di-scale menggunakan StandardScaler\")\n",
    "print(f\"Scaled data shape: {X_cluster_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52a1772",
   "metadata": {},
   "source": [
    "### 5.2 Elbow Method - Menentukan K Optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211bce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow Method\n",
    "print(\"=\"*60)\n",
    "print(\"ELBOW METHOD\")\n",
    "print(\"=\"*60)\n",
    "print(\"Mencari K optimal (2-10)...\")\n",
    "\n",
    "inertias = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_cluster_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    print(f\"K={k}: Inertia={kmeans.inertia_:.2f}\")\n",
    "\n",
    "# Plot Elbow Curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(K_range, inertias, marker='o', linewidth=2, markersize=8)\n",
    "plt.xlabel('Number of Clusters (K)', fontsize=12)\n",
    "plt.ylabel('Inertia (Within-Cluster Sum of Squares)', fontsize=12)\n",
    "plt.title('Elbow Method - Determining Optimal K', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(K_range)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Dari grafik Elbow, K optimal dapat ditentukan di titik 'siku' kurva\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a144d8e",
   "metadata": {},
   "source": [
    "### 5.3 K-Means Clustering dengan K=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403c43eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train K-Means dengan K=4\n",
    "optimal_k = 4\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"K-MEANS CLUSTERING (K={optimal_k})\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "df_cluster['Cluster'] = kmeans.fit_predict(X_cluster_scaled)\n",
    "\n",
    "print(f\"\\nâœ“ K-Means clustering selesai!\")\n",
    "print(f\"âœ“ Inertia: {kmeans.inertia_:.2f}\")\n",
    "\n",
    "# Distribusi Cluster\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DISTRIBUSI CLUSTER\")\n",
    "print(\"=\"*60)\n",
    "print(df_cluster['Cluster'].value_counts().sort_index())\n",
    "\n",
    "# Visualisasi distribusi\n",
    "plt.figure(figsize=(8, 5))\n",
    "df_cluster['Cluster'].value_counts().sort_index().plot(kind='bar', color=['#3498db', '#e74c3c', '#2ecc71', '#f39c12'])\n",
    "plt.title(f'Customer Distribution Across {optimal_k} Clusters', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Number of Customers')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf4ce4a",
   "metadata": {},
   "source": [
    "### 5.4 Analisis & Interpretasi Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b11993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profil Cluster\n",
    "print(\"=\"*60)\n",
    "print(\"PROFIL SETIAP CLUSTER\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "cluster_profile = df_cluster.groupby('Cluster')[cluster_features].mean()\n",
    "print(\"\\nRata-rata fitur per cluster:\")\n",
    "print(cluster_profile.round(2))\n",
    "\n",
    "# Visualisasi Heatmap\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(cluster_profile.T, annot=True, fmt='.2f', cmap='YlOrRd', cbar_kws={'label': 'Average Value'})\n",
    "plt.title('Cluster Profile Heatmap', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Features')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Interpretasi Cluster\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INTERPRETASI CLUSTER\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for cluster_id in range(optimal_k):\n",
    "    profile = cluster_profile.loc[cluster_id]\n",
    "    print(f\"\\nðŸ“Œ CLUSTER {cluster_id}:\")\n",
    "    print(f\"   â€¢ TotalSpending: Â£{profile['TotalSpending']:,.2f}\")\n",
    "    print(f\"   â€¢ TotalTransaction: {profile['TotalTransaction']:.0f}\")\n",
    "    print(f\"   â€¢ TotalQuantity: {profile['TotalQuantity']:,.0f}\")\n",
    "    print(f\"   â€¢ AvgPrice: Â£{profile['AvgPrice']:.2f}\")\n",
    "    print(f\"   â€¢ Recency: {profile['Recency']:.0f} hari\")\n",
    "    print(f\"   â€¢ Jumlah customer: {(df_cluster['Cluster'] == cluster_id).sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41e1554",
   "metadata": {},
   "source": [
    "### 5.5 Visualisasi dengan PCA (2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fdbc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA untuk visualisasi 2D\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_cluster_scaled)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PCA DIMENSIONALITY REDUCTION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Original dimensions: {X_cluster_scaled.shape[1]}\")\n",
    "print(f\"Reduced dimensions: {X_pca.shape[1]}\")\n",
    "print(f\"\\nExplained variance ratio:\")\n",
    "print(f\"  PC1: {pca.explained_variance_ratio_[0]:.4f} ({pca.explained_variance_ratio_[0]*100:.2f}%)\")\n",
    "print(f\"  PC2: {pca.explained_variance_ratio_[1]:.4f} ({pca.explained_variance_ratio_[1]*100:.2f}%)\")\n",
    "print(f\"  Total: {pca.explained_variance_ratio_.sum():.4f} ({pca.explained_variance_ratio_.sum()*100:.2f}%)\")\n",
    "\n",
    "# Scatter Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12']\n",
    "for cluster_id in range(optimal_k):\n",
    "    mask = df_cluster['Cluster'] == cluster_id\n",
    "    plt.scatter(X_pca[mask, 0], X_pca[mask, 1], \n",
    "                c=colors[cluster_id], label=f'Cluster {cluster_id}',\n",
    "                alpha=0.6, s=50, edgecolors='k', linewidth=0.5)\n",
    "\n",
    "# Plot centroids\n",
    "centroids_pca = pca.transform(kmeans.cluster_centers_)\n",
    "plt.scatter(centroids_pca[:, 0], centroids_pca[:, 1], \n",
    "            c='black', marker='X', s=300, linewidths=2, \n",
    "            edgecolors='white', label='Centroids')\n",
    "\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.2f}%)', fontsize=12)\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.2f}%)', fontsize=12)\n",
    "plt.title('Customer Segmentation - K-Means Clustering (PCA Visualization)', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d4cf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save hasil clustering\n",
    "output_path = 'FinalDM/Modelling/customer_segmentation_results.csv'\n",
    "df_cluster.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CLUSTERING SELESAI\")\n",
    "print(\"=\"*60)\n",
    "print(f\"âœ“ Hasil clustering disimpan: {output_path}\")\n",
    "print(f\"âœ“ Total customers: {len(df_cluster):,}\")\n",
    "print(f\"âœ“ Number of clusters: {optimal_k}\")\n",
    "print(f\"âœ“ Features used: {cluster_features}\")\n",
    "\n",
    "df_cluster.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b819d66",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Kesimpulan\n",
    "\n",
    "### Preprocessing\n",
    "- Data transaksi berhasil dibersihkan dari missing values, duplikat, dan nilai negatif\n",
    "- Feature engineering berhasil menambahkan fitur TotalAmount dan fitur waktu\n",
    "- Data diagregasi ke level customer dengan fitur RFM (Recency, Frequency, Monetary)\n",
    "\n",
    "### Classification (High Value Customer)\n",
    "- **Logistic Regression** dan **Random Forest** berhasil memprediksi HVC\n",
    "- Model dievaluasi menggunakan Accuracy, Precision, Recall, dan F1-Score\n",
    "- Features: TotalTransaction, TotalQuantity, AvgPrice, Recency (tanpa data leakage)\n",
    "\n",
    "### Clustering (Customer Segmentation)\n",
    "- **K-Means Clustering** dengan K=4 berhasil mengelompokkan customer\n",
    "- Elbow Method digunakan untuk menentukan K optimal\n",
    "- Setiap cluster memiliki karakteristik yang berbeda berdasarkan perilaku pembelian\n",
    "- Visualisasi menggunakan PCA menunjukkan separasi cluster yang jelas\n",
    "\n",
    "### Output Files\n",
    "1. `online_retail_II_preprocessed.csv` - Data transaksi yang sudah dipreprocessing\n",
    "2. `customer_aggregated.csv` - Data agregasi level customer\n",
    "3. `customer_aggregated_preprocessed.csv` - Data customer siap modeling\n",
    "4. `customer_segmentation_results.csv` - Hasil clustering dengan label cluster\n",
    "\n",
    "---\n",
    "\n",
    "**Project by: [Nama Anda]**  \n",
    "**Course: Data Mining - Semester V**  \n",
    "**Date: December 2025**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
